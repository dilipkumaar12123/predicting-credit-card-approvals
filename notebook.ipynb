{"cells":[{"source":"![Credit card being held in hand](credit_card.jpg)\n\nCommercial banks receive _a lot_ of applications for credit cards. Many of them get rejected for many reasons, like high loan balances, low income levels, or too many inquiries on an individual's credit report, for example. Manually analyzing these applications is mundane, error-prone, and time-consuming (and time is money!). Luckily, this task can be automated with the power of machine learning and pretty much every commercial bank does so nowadays. In this workbook, you will build an automatic credit card approval predictor using machine learning techniques, just like real banks do.\n\n### The Data\n\nThe data is a small subset of the Credit Card Approval dataset from the UCI Machine Learning Repository showing the credit card applications a bank receives. This dataset has been loaded as a `pandas` DataFrame called `cc_apps`. The last column in the dataset is the target value.","metadata":{},"id":"35aebf2e-0635-4fef-bc9a-877b6a20fb13","cell_type":"markdown"},{"source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\n\n# Load the dataset\ncc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \ncc_apps.head()","metadata":{"executionCancelledAt":null,"executionTime":35,"lastExecutedAt":1742040898151,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\n\n# Load the dataset\ncc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \ncc_apps.head()","outputsMetadata":{"0":{"height":260,"type":"dataFrame","tableState":{"quickFilterText":""}}},"lastExecutedByKernel":"55b188e4-5e3d-4911-acd2-8fb03598e730"},"id":"6e86b1e8-a3fa-4b09-982f-795f218bd1a6","cell_type":"code","execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"0","type":"string"},{"name":"1","type":"string"},{"name":"2","type":"number"},{"name":"3","type":"string"},{"name":"4","type":"string"},{"name":"5","type":"string"},{"name":"6","type":"string"},{"name":"7","type":"number"},{"name":"8","type":"string"},{"name":"9","type":"string"},{"name":"10","type":"integer"},{"name":"11","type":"string"},{"name":"12","type":"integer"},{"name":"13","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"0":["b","a","a","b","b"],"1":["30.83","58.67","24.50","27.83","20.17"],"2":[0,4.46,0.5,1.54,5.625],"3":["u","u","u","u","u"],"4":["g","g","g","g","g"],"5":["w","q","q","w","w"],"6":["v","h","h","v","v"],"7":[1.25,3.04,1.5,3.75,1.71],"8":["t","t","t","t","t"],"9":["t","t","f","t","f"],"10":[1,6,0,5,0],"11":["g","g","g","g","s"],"12":[0,560,824,3,0],"13":["+","+","+","+","+"],"index":[0,1,2,3,4]}},"total_rows":5,"truncation_type":null},"text/plain":"  0      1      2  3  4  5  6     7  8  9   10 11   12 13\n0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  g    0  +\n1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  g  560  +\n2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  g  824  +\n3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  g    3  +\n4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  s    0  +","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b</td>\n      <td>30.83</td>\n      <td>0.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.25</td>\n      <td>t</td>\n      <td>t</td>\n      <td>1</td>\n      <td>g</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>58.67</td>\n      <td>4.460</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>3.04</td>\n      <td>t</td>\n      <td>t</td>\n      <td>6</td>\n      <td>g</td>\n      <td>560</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>24.50</td>\n      <td>0.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>1.50</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>g</td>\n      <td>824</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b</td>\n      <td>27.83</td>\n      <td>1.540</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>3.75</td>\n      <td>t</td>\n      <td>t</td>\n      <td>5</td>\n      <td>g</td>\n      <td>3</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b</td>\n      <td>20.17</td>\n      <td>5.625</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.71</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>s</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":8}]},{"source":"Preprocess the Data by:\n1. Replacing the missing values\n2. Imputing based on Data Type\n3. Adding Missing Values with a for loop\n4. One-hot Encoding","metadata":{},"cell_type":"markdown","id":"888108d9-a3d4-46dd-80df-57410c3a3d10"},{"source":"cc_apps.replace('?', np.nan, inplace=True)\n\n# Impute missing values based on data type\nfor column in cc_apps.columns:\n    if cc_apps[column].dtype == 'object':\n        # Fill categorical columns with mode\n        cc_apps[column].fillna(cc_apps[column].mode()[0], inplace=True)\n    else:\n        # Fill numerical columns with mean\n        cc_apps[column].fillna(cc_apps[column].mean(), inplace=True)\n\n# One-hot encode categorical variables\ncc_apps = pd.get_dummies(cc_apps, drop_first=True)","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1742040898203,"lastExecutedByKernel":"55b188e4-5e3d-4911-acd2-8fb03598e730","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"cc_apps.replace('?', np.nan, inplace=True)\n\n# Impute missing values based on data type\nfor column in cc_apps.columns:\n    if cc_apps[column].dtype == 'object':\n        # Fill categorical columns with mode\n        cc_apps[column].fillna(cc_apps[column].mode()[0], inplace=True)\n    else:\n        # Fill numerical columns with mean\n        cc_apps[column].fillna(cc_apps[column].mean(), inplace=True)\n\n# One-hot encode categorical variables\ncc_apps = pd.get_dummies(cc_apps, drop_first=True)"},"cell_type":"code","id":"fce4409c-83b6-41ad-ae21-1cfccf2fb39d","outputs":[],"execution_count":9},{"source":"Preparing the data for modeling\n1. Define the target variable\n2. Splitting the data\n3. Scaling the data","metadata":{},"cell_type":"markdown","id":"a47d17f7-512b-4a38-b38b-fb98a733df18"},{"source":"# Define target and feature variables\nX = cc_apps.iloc[:, :-1]  # All columns except the last one\ny = cc_apps.iloc[:, -1]   # Last column as target\n\n# Ensure all column names are strings\nX.columns = X.columns.astype(str)\n\n# Split data into training and testing sets (80-20 split)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2025)\n\n# Scale the data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1742040898259,"lastExecutedByKernel":"55b188e4-5e3d-4911-acd2-8fb03598e730","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define target and feature variables\nX = cc_apps.iloc[:, :-1]  # All columns except the last one\ny = cc_apps.iloc[:, -1]   # Last column as target\n\n# Ensure all column names are strings\nX.columns = X.columns.astype(str)\n\n# Split data into training and testing sets (80-20 split)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2025)\n\n# Scale the data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)"},"cell_type":"code","id":"e4f3715d-3f1b-4513-9542-36bfeaa3f1c6","outputs":[],"execution_count":10},{"source":"Training the model\n1. Instantiating the model. I use Logistic Regression for this purpose.\n2. Fitting the model.\n3. Generating and evaluating the predictions.","metadata":{},"cell_type":"markdown","id":"be119600-dee8-47a6-9106-781e9eb20603"},{"source":"# Instantiate a logistic regression model\nmodel = LogisticRegression()\n\n# Fit the model to the training data\nmodel.fit(X_train, y_train)\n\n# Generate predictions\ny_pred = model.predict(X_test)\n\n# Evaluate the model using a confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", conf_matrix)","metadata":{"executionCancelledAt":null,"executionTime":162,"lastExecutedAt":1742040898422,"lastExecutedByKernel":"55b188e4-5e3d-4911-acd2-8fb03598e730","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Instantiate a logistic regression model\nmodel = LogisticRegression()\n\n# Fit the model to the training data\nmodel.fit(X_train, y_train)\n\n# Generate predictions\ny_pred = model.predict(X_test)\n\n# Evaluate the model using a confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", conf_matrix)","outputsMetadata":{"0":{"height":80,"type":"stream"}}},"cell_type":"code","id":"43537506-9ccd-4d93-b786-80b17126662c","outputs":[{"output_type":"stream","name":"stdout","text":"Confusion Matrix:\n [[38 15]\n [16 69]]\n"}],"execution_count":11},{"source":"Finding the best scoring model\n1. Defining grid search parameters\n2. Performing grid search cross validation\n3. Find the model with the best score","metadata":{},"cell_type":"markdown","id":"d774343f-b58a-4526-a639-ce4e8eeb4d84"},{"source":"# Define grid search parameters\nparam_grid = {\n    'C': [0.01, 0.1, 1, 10, 100],\n    'penalty': ['l1', 'l2'],\n    'solver': ['liblinear']\n}\n\n# Perform grid search cross-validation\ngrid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')\ngrid_search.fit(X_train, y_train)\n\n# Find the best model\nbest_model = grid_search.best_estimator_\nbest_params = grid_search.best_params_\nbest_score = grid_search.best_score_\n\nprint(\"Best Parameters:\", best_params)\nprint(\"Best Cross-Validation Score:\", best_score)","metadata":{"executionCancelledAt":null,"executionTime":8848,"lastExecutedAt":1742040907270,"lastExecutedByKernel":"55b188e4-5e3d-4911-acd2-8fb03598e730","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define grid search parameters\nparam_grid = {\n    'C': [0.01, 0.1, 1, 10, 100],\n    'penalty': ['l1', 'l2'],\n    'solver': ['liblinear']\n}\n\n# Perform grid search cross-validation\ngrid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')\ngrid_search.fit(X_train, y_train)\n\n# Find the best model\nbest_model = grid_search.best_estimator_\nbest_params = grid_search.best_params_\nbest_score = grid_search.best_score_\n\nprint(\"Best Parameters:\", best_params)\nprint(\"Best Cross-Validation Score:\", best_score)","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"cell_type":"code","id":"2069ebba-90fc-4cfd-9727-9bf3ee35537a","outputs":[{"output_type":"stream","name":"stdout","text":"Best Parameters: {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\nBest Cross-Validation Score: 0.8604586404586405\n"}],"execution_count":12}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}